# RLM Retrieval for Claude Code

![Accuracy](https://img.shields.io/badge/accuracy-99.98%25-brightgreen) ![Tests](https://img.shields.io/badge/tests-4%2C457-blue) ![License](https://img.shields.io/badge/license-MIT-green)

**99.98% accuracy** on 4,457 tests | [Benchmarks](#benchmarks) | [Install](#installation) | [Blog Post](https://gist.github.com/vriveras/79c65e1d7f34c84ccd811d6f2333535b)

<p align="center">
  <img src="docs/images/results-overall.png" width="400" alt="99.98% Accuracy">
</p>

RLM retrieval (rlm-get, rlm-state, rlm-check) for Claude Code. Never lose context between sessions.

**New in v3.1:** Claude Code *tool hooks* (settings.json) for debounced index refresh + stop-time transcript dump.

## Commands

| Command | Purpose |
|---------|---------|
| `rlm-get` | **Mandatory** state retrieval before answering history questions |
| `rlm-state` | Show context state, active topics, threads |
| `rlm-check` | Validate retrieval accuracy |

Based on the [Recursive Language Models](https://arxiv.org/abs/2512.24601) paper â€” search raw transcripts, don't summarize them.

## How It Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           HYBRID RETRIEVAL                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  Query arrives: "what did we decide about auth?"                           â”‚
â”‚       â†“                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚ ğŸ”® Semantic Search      â”‚    â”‚ ğŸ” RLM Retrieval        â”‚                â”‚
â”‚  â”‚                         â”‚    â”‚                         â”‚                â”‚
â”‚  â”‚ â€¢ Paraphrases           â”‚    â”‚ â€¢ Substring matching    â”‚                â”‚
â”‚  â”‚ â€¢ Conceptual similarity â”‚    â”‚ â€¢ Compound splitting    â”‚                â”‚
â”‚  â”‚ â€¢ Fuzzy intent          â”‚    â”‚ â€¢ Fuzzy (Levenshtein)   â”‚                â”‚
â”‚  â”‚                         â”‚    â”‚ â€¢ Concept expansion     â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â”‚                          â†“                                                  â”‚
â”‚                 Merge & dedupe results                                      â”‚
â”‚                          â†“                                                  â”‚
â”‚         ğŸ§  Return with source indicator                                     â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Enhanced Matching (99.98% Accuracy)

Four matching strategies combine for near-perfect recall:

| Strategy | Example |
|----------|---------|
| **Substring** | "Glicko" matches "Glicko-2 rating system" |
| **Compound splitting** | "ReadMessageItem" â†’ read, message, item |
| **Fuzzy (Levenshtein â‰¤ 2)** | "postgres" â‰ˆ "PostgreSQL" |
| **Concept expansion** | "glicko" â†’ rating, chess, elo |

### Latency Tradeoff

| Mode | Latency | Recall |
|------|---------|--------|
| Basic | 0.02ms | 74% |
| Enhanced | 14.78ms | **100%** |

+26% recall for +14.76ms â€” worth it.

## Installation

### Option 1: Claude Code Plugin (recommended)

```bash
# Install the plugin
claude plugin add vriveras/claude-rlm-retrieval
```

Then, in your project:

```bash
cp -r ~/.claude/skills/rlm-retrieval ./skills/rlm-retrieval
mkdir -p .claude-memory/transcripts
```

(Optional but recommended) Enable hooks by merging `hooks/hooks.json` into `~/.claude/settings.json`.

### Option 2: Manual Install

```bash
# Clone the repo
git clone https://github.com/vriveras/claude-rlm-retrieval.git
cd claude-rlm-retrieval

# Run installer
python install.py

# Or manually copy to your project's .claude/ folder
```

### Option 3: Copy Scripts Only

Just copy `scripts/` to your project. The core is:
- `enhanced_matching.py` â€” the 99.98% matching engine
- `search.py` â€” hybrid search with temporal awareness
- `temporal_parser.py` â€” understands "yesterday", "last week", etc.

## Usage

### RLM Indicator

When memory retrieval helps answer a question, you'll see indicators:

| Indicator | Meaning |
|-----------|---------|
| ğŸ”® | Found via **semantic search** |
| ğŸ” | Found via **RLM keyword search** |
| ğŸ§  | Found via **both methods** (highest confidence) |

```
ğŸ§  (01-29) We decided to use PKCE for the OAuth flow.

ğŸ” The exact error was: ECONNREFUSED 127.0.0.1:5432

ğŸ”® We discussed authentication patterns yesterday.
```

### Commands

| Command | Action |
|---------|--------|
| `/context-init` | Initialize memory for this project |
| `/context-state` | Show stats + active topics/threads/decisions |
| `/context-save` | Update state.json with current context |
| `/context-resume` | Load and continue from last session |
| `what did we decide about X` | Search decisions (shows ğŸ§ ) |
| `where were we` | Show active threads |

### Context State

```
ğŸ§  Project Memory Status
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“ Project: my-project

ğŸ“Š System Stats
   â€¢ Chunks indexed: 47
   â€¢ State entries: 14 (3 topics, 4 threads, 7 decisions)
   â€¢ Latest update: 2026-01-30

ğŸ“ Active Topics: auth, api-design, database

ğŸ§µ Open Threads
   â€¢ oauth-flow (active) â€” Implementing OAuth2 PKCE
   â€¢ api-routes (done)

ğŸ“‹ Recent Decisions
   â€¢ 01-30: Use raw transcripts, not summaries
   â€¢ 01-29: Use refresh tokens with 7-day expiry
```

## Temporal Queries

The skill understands natural time references:

| Query | Parsed As |
|-------|-----------|
| "what did we do yesterday?" | Previous day |
| "last week's discussions" | 7 days ago to yesterday |
| "3 days ago" | Specific date |
| "on Monday" | Most recent Monday |
| "recently" | Last 7 days |

## Architecture

```
<project>/
â”œâ”€â”€ .claude-memory/
â”‚   â”œâ”€â”€ state.json         â† Topics, threads, decisions, entities
â”‚   â”œâ”€â”€ conv-*.md          â† Conversation chunks (if using chunk storage)
â”‚   â””â”€â”€ sessions-index.json â† Session metadata for fast filtering
â””â”€â”€ ...

scripts/
â”œâ”€â”€ enhanced_matching.py   â† 4-strategy matching engine
â”œâ”€â”€ search.py              â† Hybrid search with temporal awareness  
â”œâ”€â”€ temporal_parser.py     â† Natural language time parsing
â”œâ”€â”€ save.py                â† Update state with new context
â”œâ”€â”€ resume.py              â† Load context from previous session
â”œâ”€â”€ init.py                â† Initialize memory for project
â””â”€â”€ update-state.py        â† CLI for state management
```

## Benchmarks

**Test Suite:** 4,457 auto-generated test cases across 600 synthetic conversation chunks.

### Overall Accuracy

| Metric | Value |
|--------|-------|
| **Overall** | 99.98% (4,456/4,457) |
| True Positives | 4,440 |
| True Negatives | 16 |
| False Positives | 1 |
| False Negatives | 0 |

### By Category

| Category | Tests | Accuracy |
|----------|-------|----------|
| technical | 1,785 | 100% |
| variation | 1,785 | 100% |
| identity | 868 | 100% |
| temporal | 2 | 100% |
| adversarial | 17 | 94.1% |

### Cross-Platform Parity

<p align="center">
  <img src="docs/images/cross-platform-comparison.png" width="500" alt="Cross-Platform Comparison">
</p>

| Platform | Tests | Accuracy |
|----------|-------|----------|
| Clawdbot | 4,000 | 99.8% |
| Claude Code | 4,457 | 99.98% |

Both implementations share the same `enhanced_matching.py` core.

### Results by Category

<p align="center">
  <img src="docs/images/results-by-category.png" width="600" alt="Results by Category">
</p>

## Why RLM > Summarization

From the [RLM paper](https://arxiv.org/abs/2512.24601):

1. **No information loss** â€” summaries lose detail
2. **Search is cheap** â€” RLM heuristics find relevant parts fast  
3. **Automatic** â€” transcripts already saved
4. **Flexible** â€” search for anything, not just what was "summarized"

### Compaction vs RLM

| Metric | Compaction | RLM |
|--------|------------|-----|
| Code blocks survival | 7% | 100% |
| URLs survival | 22% | 100% |
| Decisions survival | 29% | 100% |
| Tokens per fact | 91 | 40 |
| Context efficiency | 15% useful | 95% useful |

## Related

- **Clawdbot version:** [vriveras/clawdbot-context-memory](https://github.com/vriveras/clawdbot-context-memory)
- **Blog post:** [Building a 99.8% Accurate Memory System](https://gist.github.com/vriveras/79c65e1d7f34c84ccd811d6f2333535b)
- **RLM Paper:** [arxiv.org/abs/2512.24601](https://arxiv.org/abs/2512.24601)

## License

MIT
